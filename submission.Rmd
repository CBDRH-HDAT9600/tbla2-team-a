---
title: "HDAT9600 Team Based Learning Activity"
subtitle: "TBLA 2. Linear model"
author: "A. Student"
date: "01/01/1990"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(cowplot)
library(kableExtra)
```

## Instructions

Using the `prostate` dataset (which comes with the `faraway` package for R) write some R code that

1) Performs a simple exploratory data analysis (EDA)
1) Fits a linear model, with the `lpsa` variable as the outcome (response), and the `lcavol` variable as the single predictor
1) Displays the R-squared and the residual standard error (RSE) for this model
1) Adds each of the variables `lweight`, `svi`, `lbph`, `age`, `lcp`, `pgg45` and `gleason` to the model, one-by-one
1) Displays the R-squared and RSE for each of these models
1) Creates two plots, one displaying the trend in R-squared as predictor variables are successively added to each model, and another plot showing the trend in RSE as predictor variables are successively added to each model
1) Finally, briefly describe what you observe in these plots


## Accessing the data

We can use the `data()` function from the `utils` package to load the data into the R environment, and the `head()` function to take a sneak peek.

```{r}
data(prostate, package = "faraway")
head(prostate)
```

Try entering `?faraway::prostate` at the console to get more information about this dataset. 

## Submission

Work with your group to add your analysis to this file using appropriate Rmarkdown formatting and R code chunks. Add and commit your changes as you go. Once you are ready, push all your changes to submit. If necessary, check out the introductory tutorials on knitr and git. 

## Solution

### 1. Exploratory Data Analysis

In this section, we access the data and perform simple exploratory data analysis.

```{r}
str(prostate)
summary(prostate)

# Check for missing values

sum(is.na(prostate))

# Check variables with integer data type - svi, gleason and pgg45
unique(prostate$svi)
unique(prostate$gleason)
unique(prostate$pgg45)

# Convert svi and gleason to factors
prostate$svi <- as.factor(prostate$svi)
prostate$gleason <- as.factor(prostate$gleason)

summary(prostate)
```
* The `prostate` data set contains 97 observations and 9 variables. All the variables are numeric.
* There are no missing values in the data set.

#### Univariate Summaries

```{r echo = FALSE, warning = FALSE, message = FALSE}

lpsa_plot <- ggplot(data = prostate, aes(x = lpsa)) + 
              geom_histogram(color = 'skyblue4', fill = 'skyblue2') +
              scale_y_continuous(breaks = seq(0, 16, 2), lim = c(0, 16), expand = c(0, 0))

lcavol_plot <- ggplot(data = prostate, aes(x = lcavol)) + 
                geom_histogram(color = 'skyblue4', fill = 'skyblue2') +
                scale_y_continuous(breaks = seq(0, 16, 2), lim = c(0, 16), expand = c(0, 0))

lweight_plot <- ggplot(data = prostate, aes(x=lweight)) + 
                geom_histogram(color = 'skyblue4', fill = 'skyblue2') +
                scale_y_continuous(breaks = seq(0, 16, 2), lim = c(0, 16), expand = c(0, 0))

lbph_plot <- ggplot(data = prostate, aes(x=lbph)) + 
                geom_histogram(color = 'skyblue4', fill = 'skyblue2') +
                scale_y_continuous(breaks = seq(0, 16, 2), lim = c(0, 16), expand = c(0, 0))

age_plot <- ggplot(data = prostate, aes(x=age)) + 
                geom_histogram(color = 'skyblue4', fill = 'skyblue2') +
                scale_y_continuous(breaks = seq(0, 16, 2), lim = c(0, 16), expand = c(0, 0))

lcp_plot <- ggplot(data = prostate, aes(x=lcp)) + 
                geom_histogram(color = 'skyblue4', fill = 'skyblue2') +
                scale_y_continuous(breaks = seq(0, 16, 2), lim = c(0, 16), expand = c(0, 0))

pgg45_plot <- ggplot(data = prostate, aes(x=pgg45)) + 
                geom_histogram(color = 'skyblue4', fill = 'skyblue2') +
                scale_y_continuous(breaks = seq(0, 16, 2), lim = c(0, 16), expand = c(0, 0))

svi_plot <- ggplot(data = prostate, aes(x = svi)) +
                geom_bar(color = 'goldenrod4', fill = 'goldenrod2', width = 0.5) +
                scale_y_continuous(breaks = seq(0, 80, 10))

gleason_plot <- ggplot(data = prostate, aes(x = gleason)) +
                geom_bar(color = 'goldenrod4', fill = 'goldenrod2', width = 0.7) +
                scale_y_continuous(breaks = seq(0, 60, 10))



plot_grid(lpsa_plot, lcavol_plot, lweight_plot, lbph_plot, nrow = 2, ncol = 2)


plot_grid(age_plot, lcp_plot, pgg45_plot, nrow = 2, ncol = 2)

plot_grid(svi_plot, gleason_plot, nrow = 1, ncol = 2)
```

#### Bivariate Summaries 

```{r echo = FALSE, warning = FALSE, message = FALSE}
p1 <- ggplot(prostate, aes(lcavol, lpsa)) +
      geom_point(color = 'black', size = 2) 

p2 <- ggplot(prostate, aes(lweight, lpsa)) +
      geom_point(color = 'green4', size = 2)

p3 <- ggplot(prostate, aes(lbph, lpsa)) +
      geom_point(color = 'coral1', size = 2)

p4 <- ggplot(prostate, aes(age, lpsa)) +
      geom_point(color = 'red3', size = 2)

p4 <- ggplot(prostate, aes(age, lpsa)) +
      geom_point(color = 'red3', size = 2)

p5 <- ggplot(prostate, aes(lcp, lpsa)) +
      geom_point(color = 'goldenrod3', size = 2)

p6 <- ggplot(prostate, aes(pgg45, lpsa)) +
      geom_point(color = 'orchid4', size = 2)

p7 <- ggplot(prostate, aes(svi, lpsa, fill = svi)) +
      geom_boxplot(alpha = 0.3) +
      theme(legend.position = "none")

p8 <- ggplot(prostate, aes(gleason, lpsa, fill = gleason)) +
      geom_boxplot(alpha = 0.3) +
      theme(legend.position = "none")

plot_grid(p1, p2, p3, p4, 
          labels = c('lpsa vs. lcavol', 'lpsa vs. lweight', 'lpsa vs. lbph', 'lpsa vs. age'),
          label_size = 10, 
          nrow = 2, ncol = 2)

plot_grid(p5, p6, p7, p8, 
          labels = c('lpsa vs. lcp', 'lpsa vs. pgg45', 'lpsa vs. svi', 'lpsa vs. gleason'),
          label_size = 10, 
          nrow = 2, ncol = 2)

```

##### 2. Fit a linear model, with the `lpsa` variable as the outcome (response), and the `lcavol` variable as the single predictor

The R code to fit the model: __lpsa = $\beta_{0}$ + $\beta_{1}$lcavol + $\epsilon$__  
via OLS is 

```{r }
mod1 <- lm(lpsa ~ lcavol, data = prostate)
```

##### 3. Display the R-squared and the residual standard error (RSE) for this model


```{r}
mod1_R2 <- summary(mod1)$r.squared
mod1_R2_adjusted <- summary(mod1)$adj.r.squared
mod1_R2
mod1_R2_adjusted

mod1_RSE <- summary(mod1)$sigma
mod1_RSE

```
#### 4-5. Add each of the variables `lweight`, `svi`, `lbph`, `age`, `lcp`, `pgg45` and `gleason` to the model, one-by-one. Displays the R-squared and RSE for each of these models

* The R code to fit the model: __lpsa = $\beta_{0}$ + $\beta_{1}$lcavol + $\beta_{2}$lweight + $\epsilon$__  
via OLS is 

```{r }
mod2 <- lm(lpsa ~ lcavol + lweight, data = prostate)
#summary(mod2)

mod2_R2 <- summary(mod2)$r.squared
mod2_R2_adjusted <- summary(mod2)$adj.r.squared
mod2_R2
mod2_R2_adjusted

mod2_RSE <- summary(mod2)$sigma
mod2_RSE
```
* The R code to fit the model: __lpsa = $\beta_{0}$ + $\beta_{1}$lcavol + $\beta_{2}$lweight + $\beta_{3}$svi + $\epsilon$__  
via OLS is 

```{r }
mod3 <- lm(lpsa ~ lcavol + lweight + svi, data = prostate)
#summary(mod3)

mod3_R2 <- summary(mod3)$r.squared
mod3_R2_adjusted <- summary(mod3)$adj.r.squared
mod3_R2
mod3_R2_adjusted

mod3_RSE <- summary(mod3)$sigma
mod3_RSE
```
* The R code to fit the model: __lpsa = $\beta_{0}$ + $\beta_{1}$lcavol + $\beta_{2}$lweight + $\beta_{3}$svi + $\beta_{4}$lbph + $\epsilon$__  
via OLS is 

```{r }
mod4 <- lm(lpsa ~ lcavol + lweight + svi + lbph, data = prostate)
summary(mod4)

mod4_R2 <- summary(mod4)$r.squared
mod4_R2_adjusted <- summary(mod4)$adj.r.squared
mod4_R2
mod4_R2_adjusted

mod4_RSE <- summary(mod4)$sigma
mod4_RSE
```
* The R code to fit the model: __lpsa = $\beta_{0}$ + $\beta_{1}$lcavol + $\beta_{2}$lweight + $\beta_{3}$svi + $\beta_{4}$lbph + $\beta_{5}$age + $\epsilon$__  
via OLS is 

```{r }
mod5 <- lm(lpsa ~ lcavol + lweight + svi + lbph + age, data = prostate)
summary(mod5)

mod5_R2 <- summary(mod5)$r.squared
mod5_R2_adjusted <- summary(mod5)$adj.r.squared
mod5_R2
mod5_R2_adjusted

mod5_RSE <- summary(mod5)$sigma
mod5_RSE

```
* The R code to fit the model: __lpsa = $\beta_{0}$ + $\beta_{1}$lcavol + $\beta_{2}$lweight + $\beta_{3}$svi + $\beta_{4}$lbph + $\beta_{5}$age + $\beta_{6}$lcp + $\epsilon$__  
via OLS is 

```{r }
mod6 <- lm(lpsa ~ lcavol + lweight + svi + lbph + age + lcp, data = prostate)
summary(mod6)

mod6_R2 <- summary(mod6)$r.squared
mod6_R2_adjusted <- summary(mod6)$adj.r.squared
mod6_R2
mod6_R2_adjusted

mod6_RSE <- summary(mod6)$sigma
mod6_RSE

```
* The R code to fit the model: __lpsa = $\beta_{0}$ + $\beta_{1}$lcavol + $\beta_{2}$lweight + $\beta_{3}$svi + $\beta_{4}$lbph + $\beta_{5}$age + $\beta_{6}$lcp + $\beta_{7}$pgg45 + $\epsilon$__  
via OLS is 

```{r }
mod7 <- lm(lpsa ~ lcavol + lweight + svi + lbph + age + lcp + pgg45, data = prostate)
summary(mod7)

mod7_R2 <- summary(mod7)$r.squared
mod7_R2_adjusted <- summary(mod7)$adj.r.squared
mod7_R2
mod7_R2_adjusted

mod7_RSE <- summary(mod7)$sigma
mod7_RSE

```

* The R code to fit the model: __lpsa = $\beta_{0}$ + $\beta_{1}$lcavol + $\beta_{2}$lweight + $\beta_{3}$svi + $\beta_{4}$lbph + $\beta_{5}$age + $\beta_{6}$lcp + $\beta_{7}$pgg45 + $\beta_{8}$gleason + $\epsilon$__  
via OLS is 

```{r }
mod8 <- lm(lpsa ~ lcavol + lweight + svi + lbph + age + lcp + pgg45 + gleason, data = prostate)
summary(mod8)

mod8_R2 <- summary(mod8)$r.squared
mod8_R2_adjusted <- summary(mod8)$adj.r.squared
mod8_R2
mod8_R2_adjusted

mod8_RSE <- summary(mod8)$sigma
mod8_RSE

```

***

#### 6. Create two plots, one displaying the trend in R-squared as predictor variables are successively added to each model, and another plot showing the trend in RSE as predictor variables are successively added to each model

* Plot 1: R-squared vs Linear Models

```{r echo = FALSE}
# create a new dataframe

modelnum <- c('LM 1', 'LM 2', 'LM 3', 'LM 4',
               'LM 5', 'LM 6', 'LM 7', 'LM 8')


pred_vars <- c('lcavol', 
               'lcavol + lweight',
               'lcavol + lweight + svi',
               'lcavol + lweight + svi + lbph',
               'lcavol + lweight + svi + lbph + age',
               'lcavol + lweight + svi + lbph + age + lcp', 
               'lcavol + lweight + svi + lbph + age + lcp + pgg45',
               'lcavol + lweight + svi + lbph + age + lcp + pgg45 + gleason')


adj_Rsquared <- c(mod1_R2_adjusted, mod2_R2_adjusted, mod3_R2_adjusted, mod4_R2_adjusted,
                   mod5_R2_adjusted, mod6_R2_adjusted, mod7_R2_adjusted, mod8_R2_adjusted)

r2_pred_vars <- data.frame("Linear Model" = modelnum,
                           "Predictor Variables" = pred_vars,
                           "R-Squared" = adj_Rsquared)

#print(r2_pred_vars, right = FALSE)

kbl(r2_pred_vars, caption = "Linear Models (LM) and their R-squared values") %>% kable_styling()
```

***

```{r echo = FALSE, fig.align='center'}


ggplot(data = r2_pred_vars, aes(x = modelnum, y = adj_Rsquared)) +
  geom_point(color = "darkred", size = 2, shape = 4, stroke = 2) + 
  labs(title = "R-squared (adjusted) values at different linear models (Prostate dataset)",
       y = "R-squared (adjusted) values",
       x = "Linear Models (see Table)") +
  ylim(0.5, 0.7)


```

***

* Plot 2: R-squared vs Linear Models

```{r echo = FALSE}
# create a new dataframe


adj_Rsquared <- c(mod1_R2_adjusted, mod2_R2_adjusted, mod3_R2_adjusted, mod4_R2_adjusted,
                   mod5_R2_adjusted, mod6_R2_adjusted, mod7_R2_adjusted, mod8_R2_adjusted)


RSE_lm <- c(mod1_RSE, mod2_RSE, mod3_RSE, mod4_RSE,
         mod5_RSE, mod6_RSE, mod7_RSE, mod8_RSE)

RSE_pred_vars <- data.frame("Linear Model" = modelnum,
                           "Predictor Variables" = pred_vars,
                           "RSE" = RSE_lm)


kbl(RSE_pred_vars, caption = "Linear Models (LM) and their Residual Standard Errors (RSE)") %>% kable_styling()

```

***

```{r echo = FALSE, fig.align='center'}


ggplot(data = RSE_pred_vars, aes(x = modelnum, y = RSE_lm)) +
  geom_point(color = "navyblue", size = 2, shape = 4, stroke = 2) + 
  labs(title = "Residual Standard Errors (RSE) values at different linear models (Prostate dataset)",
       y = "Residual Standard Errors (RSE)",
       x = "Linear Models (see Table)") +
  ylim(0.6, 0.85)


```
***


# Try using lappy





















